import torch
import torchvision
import os

download = True
if os.path.exists("MNIST"):
    download = False

is_cuda = torch.cuda.is_available()

# load mnist training and test datasets.
train_data = torchvision.datasets.MNIST(root="./", download=download, transform=torchvision.transforms.ToTensor())

# function to encode mnist image into a one-hot-like tensor.
# each pixel value is expanded into a 256-dimensional vector with a single active value.
def encode_input(x):
    x_expanded = torch.zeros(784, 256, device=x.device)
    for i in range(784):
        x_expanded[i, int(x[i] * 255)] = 1
    return x_expanded

# define the Oracle model that predicts program rules.
class Oracle(torch.nn.Module):
    def __init__(self):
        super().__init__()
        # define a small neural network with two linear layers.
        self.lin1 = torch.nn.Linear(784 * 256, 8)  # first layer reduces input size significantly.
        self.lin2 = torch.nn.Linear(8, 784 * 256 * 10 * 2)  # outputs possible binary rules.
    
    def forward(self, x):
        x = self.lin1(x.view(-1))  # flatten input and pass through first layer.
        x = self.lin2(x)  # second layer generates raw predictions.
        x = x.view(784, 256, 10, 2)  # reshape output to match rules format.
        # use gumbel-softmax to produce binary decisions (0 or 1).
        decisions = torch.nn.functional.gumbel_softmax(x, hard=True, dim=-1)
        return decisions[..., 1]  # return binary program (only "1" decisions).

# define the ProgramState class that uses the learned rules.
class ProgramState(torch.nn.Module):
    def __init__(self):
        super().__init__()
        # initialize rules buffer to hold learned binary rules.
        self.register_buffer('rules', torch.zeros((784, 256, 10)))
    
    def update_rules(self, new_rules):
        # update rules with the ones generated by the Oracle.
        self.rules = new_rules
    
    def compute(self, x_expanded):
        # apply rules to encoded input to compute active pixels and sum their contributions.
        active_pixels = (x_expanded.unsqueeze(-1)) * self.rules
        return active_pixels.sum(dim=(0, 1))

# initialize models and optimizer.
program_state = ProgramState()
oracle = Oracle()
if is_cuda:
    program_state.to("cuda")
    oracle.to("cuda")
optimizer = torch.optim.Adam(oracle.parameters())

# training loop.
losses = []
correct_predictions = 0
total_predictions = 0

for i in range(len(train_data)):
    optimizer.zero_grad()
    img, label = train_data[i]
    X = img.view(-1)
    if is_cuda:
        X = X.to("cuda")
    X_encoded = encode_input(X)  # encode input into one-hot representation.
    
    rules = oracle(X_encoded)  # predict program rules using the Oracle.
    program_state.update_rules(rules)  # update ProgramState with new rules.
    output = program_state.compute(X_encoded)  # compute output using the program.

    soft_output = torch.nn.functional.softmax(output, dim=-1)
    loss = -torch.log(soft_output[label])  # negative log-likelihood loss.
    pred = torch.argmax(soft_output).cpu().item()  # get predicted label.
    correct_predictions += (pred == label)
    total_predictions += 1
    
    loss.backward()
    losses.append(loss.item())
    optimizer.step()  # update Oracle parameters.
    
    if i % 100 == 0:  # print progress every 100 steps.
        avg_loss = sum(losses) / len(losses)
        accuracy = (correct_predictions / total_predictions) * 100
        print(f"loss: {avg_loss:.4f}")
        print(f"accuracy: {accuracy:.2f}%")
        print(f"active rules: {(rules == 1).sum().item()}")
        losses = []
        correct_predictions = 0
        total_predictions = 0
        
        # save the learned binary program.
        torch.save(program_state.rules, "binary_program.pth")
        print("binary program saved to binary_program.pth")
